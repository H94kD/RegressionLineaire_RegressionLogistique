{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7167e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import mysql.connector\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d74dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_page2():\n",
    "    urls=[]\n",
    "    page_number = 1\n",
    "    \n",
    "    for i in range(50):\n",
    "        i = f\"https://books.toscrape.com/catalogue/page-{page_number}.html\"\n",
    "        page_number += 1\n",
    "        urls.append(i)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbcf456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les détails d'un livre\n",
    "def extract_book_details2(book):\n",
    "    \n",
    "    # book c'est la section d'une page qui contient un livre. c'est dans cette section on va extraire le lien pour \n",
    "    # entrer dans la page d'un livre\n",
    "    \n",
    "    #book_url c'est le lien pour entrer sur la page d'un livre \n",
    "    book_url = book.find('div', class_='image_container').a[\"href\"]\n",
    "    \n",
    "    # URL de base pour arriver sur un livre en particulier\n",
    "    base_url = 'https://books.toscrape.com/catalogue/'\n",
    "    \n",
    "    #former le lien complet du livre sur la page en concatenant book_url et base_url\n",
    "    lien_complet = urljoin(base_url,  book_url)\n",
    "    url_book = lien_complet\n",
    "    #print(url_book)\n",
    "    \n",
    "    # extraire les informations du livre dans sa page\n",
    "    response = requests.get(lien_complet) #ouvrir la page \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')  # transformer en beautifulsoup\n",
    "\n",
    "    title = soup.find('h1').text.strip() # le titre du livre\n",
    "    p = soup.find('p', class_='price_color').text.strip() # le prix tout taxe\n",
    "    priceTTC = re.search(r'\\d+\\.\\d+', p).group() # retrait du symbole de l'euro\n",
    "    \n",
    "    #extraire la disponibilite du produit\n",
    "    chaine = soup.find('p', class_='instock availability').text.strip()\n",
    "    availability = re.search(r'^\\w+\\s\\w+', chaine).group()\n",
    "    \n",
    "    #extraire la quantite du produit\n",
    "    stock = re.search(r'\\d+', chaine).group()\n",
    "    \n",
    "    #extraire le raiting\n",
    "    rating_class = soup.find('p', class_='star-rating')['class'][1]\n",
    "    rating = rating_class.strip() \n",
    "    \n",
    "    #extraire le lien vers l'image du livre\n",
    "    base_url2 = 'https://books.toscrape.com/media/'  # url de base pour les images\n",
    "    im = soup.find('div', class_='item active').img[\"src\"]\n",
    "    chemin_relatif2 = '/'.join(im.split('/')[3:]) # Extraire le chemin relatif de l'image\n",
    "    image_url = urljoin(base_url2, chemin_relatif2)\n",
    "    \n",
    "    #extraire la categorie du produit\n",
    "    li_tags = soup.find('ul', class_='breadcrumb')\n",
    "    li = li_tags.find_all('li')\n",
    "    # L'avant-dernier li\n",
    "    category = li[-2].get_text(strip=True)\n",
    "    #print(category)\n",
    "    \n",
    "    \n",
    "    #extraire la taxe\n",
    "    t = soup.find('table', class_='table table-striped')\n",
    "    tr=t.find_all('tr')\n",
    "    taxe = tr[4].td.get_text(strip=True)\n",
    "    #print(taxe)\n",
    "    \n",
    "    # extraire number of reviews\n",
    "    n= soup.find('table', class_='table table-striped')\n",
    "    tr=n.find_all('tr')\n",
    "    reviews = tr[6].td.get_text(strip=True)\n",
    "    #print(reviews)\n",
    "    \n",
    "    # Créer une liste pour stocker les données de chaque élément\n",
    "    data = []\n",
    "    data.append([title, priceTTC, availability,stock, image_url,url_book, rating, category])\n",
    "    with open('produits_extrait.csv', mode='a', newline='',encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        #writer.writerow(['title', 'price', 'availability', 'image_url','book_url', 'Rating','category'])\n",
    "        writer.writerows(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d27bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on scrapehttps://books.toscrape.com/catalogue/page-1.html\n",
      "\n",
      "on scrapehttps://books.toscrape.com/catalogue/page-2.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_all_page2():\n",
    "    page = get_all_page2()# recuperer la liste des liens vers toutes les pages\n",
    "    n=[]\n",
    "    for p in page: # p c'est le lien d'une page\n",
    "        r = requests.get(p) # ouvrir une page\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        books = soup.find_all('article', class_='product_pod') # recupere les sections de tous les livres de la page\n",
    "        \n",
    "        print(f\"on scrape{p}\\n\")\n",
    "        for b in books: # pour un livre particulier b\n",
    "            n.append(extract_book_details2(book=b)) # extraire les details de ce livre et ajouter a la liste n\n",
    "        \n",
    "    print(len(n))\n",
    "    return n\n",
    "datasetfin = []\n",
    "datasetfin=parse_all_page2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4208d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorie():\n",
    "    # URL de base\n",
    "    base_url = 'https://books.toscrape.com/'\n",
    "\n",
    "    # Récupérer la page d'accueil\n",
    "    response = requests.get(base_url + 'index.html')\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Récupérer la liste des catégories et supprimer la première catégorie\n",
    "    categories = soup.find('ul', class_='nav-list').find_all('li')\n",
    "    categories.pop(0)  # Supprimer la première catégorie\n",
    "    nomsCategories = []\n",
    "    for cat in categories:\n",
    "        nomsCategories.append(cat.a.text.strip())\n",
    "    return nomsCategories\n",
    "c = get_categorie()\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325cdd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_client = pd.read_csv('produits_extrait.csv',names=['title', 'price', 'availability','stock', 'image_url','book_url' ,'rating', 'category'],header=None,index_col=False)\n",
    "\n",
    "data_client['rating'] = data_client['rating'].replace({'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5})\n",
    "data_client.head(50)\n",
    "#print(data_client['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a42dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifier les donnees manquantes avec `isna()`\n",
    "missing_data = data_client.isna().sum()\n",
    "\n",
    "# afficher les donnees manquantes\n",
    "print(\"Données manquantes par colonne :\")\n",
    "print(missing_data)\n",
    "\n",
    "# chercher les lignes avec les donnees manquantes `any()`\n",
    "rows_with_missing_data = data_client.isnull().any(axis=1)\n",
    "\n",
    "# afficher le nombre de ligne avec les donnees manquantes\n",
    "print(\"\\nNombre de lignes avec des données manquantes :\", rows_with_missing_data.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#les 5 premiers\n",
    "p = data_client.sort_values(by='price').head(10)\n",
    "p\n",
    "\n",
    "# Créer un graphique à barres\n",
    "plt.figure(figsize=(15, 8))\n",
    "bars = plt.bar(p['title'], p['price'], width=0.5,color=['lightblue', 'lightgreen', 'lightcoral', 'lightsalmon', 'lightseagreen'])\n",
    "\n",
    "# Annoter chaque barre avec le montant de la vente\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
    "\n",
    "# Abbreviation de l'axe des x\n",
    "abbreviated_titles = [title[:20] + '...' if len(title) > 20 else title for title in p['title']]\n",
    "plt.xticks(range(len(p)), abbreviated_titles, rotation=45, ha='right')\n",
    "\n",
    "plt.xticks(range(len(p)), rotation=45, ha='right') \n",
    "plt.xlabel('Livres', fontsize=12, weight='bold')\n",
    "plt.ylabel('Prix', fontsize=12, weight='bold')\n",
    "\n",
    "# Ajouter une grille pour une meilleure lisibilité\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1173972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#trier le dataframe par ordre decroissant\n",
    "p = data_client.sort_values(by='price', ascending=False).head(10)\n",
    "p\n",
    "# Créer un graphique à barres\n",
    "plt.figure(figsize=(15, 8))\n",
    "bars = plt.bar(p['title'], p['price'], width=0.5, color = ['lightgreen', 'lightblue', 'gray', 'brown', 'lightgray'])\n",
    "\n",
    "# Annoter chaque barre avec le montant de la vente\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
    "\n",
    "# Abbreviation de l'axe des x\n",
    "abbreviated_titles = [title[:20] + '...' if len(title) > 20 else title for title in p['title']]\n",
    "plt.xticks(range(len(p)), abbreviated_titles, rotation=45, ha='right')\n",
    "\n",
    "# Ajouter une grille pour une meilleure lisibilité\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.xticks(range(len(p)), rotation=45, ha='right') \n",
    "plt.xlabel('Livres', fontsize=12, weight='bold')\n",
    "plt.ylabel('Prix', fontsize=12, weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#trier le dataframe par ordre decroissant\n",
    "p = data_client.sort_values(by='rating', ascending=False).head(10)\n",
    "p\n",
    "# Créer un graphique à barres\n",
    "plt.figure(figsize=(15, 8))\n",
    "bars = plt.bar(p['title'], p['rating'], width=0.5,color=['green', 'black', 'red', 'blue', 'yellow'])\n",
    "\n",
    "# Annoter chaque barre avec le montant de la vente\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
    "    \n",
    "# Abbreviation de l'axe des x\n",
    "abbreviated_titles = [title[:20] + '...' if len(title) > 20 else title for title in p['title']]\n",
    "plt.xticks(range(len(p)), abbreviated_titles, rotation=45, ha='right')\n",
    "\n",
    "# Ajouter une grille pour une meilleure lisibilité\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.xticks(range(len(p)), rotation=45, ha='right') \n",
    "plt.xlabel('Livres', fontsize=12, weight='bold')\n",
    "plt.ylabel('Rating', fontsize=12, weight='bold')\n",
    "plt.savefig('les_10_produits_les_plus_recommendes.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac90ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#les 5 premiers\n",
    "p = data_client.sort_values(by='rating').head(10)\n",
    "p\n",
    "# Créer un graphique à barres\n",
    "plt.figure(figsize=(15, 8))\n",
    "bars = plt.bar(p['title'], p['rating'], width=0.5,color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])\n",
    "\n",
    "# Annoter chaque barre avec le montant de la vente\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
    "\n",
    "# Abbreviation de l'axe des x\n",
    "abbreviated_titles = [title[:20] + '...' if len(title) > 20 else title for title in p['title']]\n",
    "plt.xticks(range(len(p)), abbreviated_titles, rotation=45, ha='right')\n",
    "\n",
    "# Ajouter une grille pour une meilleure lisibilité\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.xticks(range(len(p)), rotation=45, ha='right') \n",
    "plt.xlabel('Livres', fontsize=12, weight='bold')\n",
    "plt.ylabel('Rating', fontsize=12, weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un diagramme circulaire des catégories ayant le plus grand nombre de livres en stock\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(p, labels=p.index, autopct=\"%1.1f%%\", labeldistance=1.1, textprops={'fontsize': 12, 'weight': 'bold'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un diagramme circulaire des catégories ayant le plus grand nombre de livres en stock\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Définir les couleurs à utiliser dans le graphique\n",
    "colors = plt.cm.tab10.colors\n",
    "\n",
    "# Diagramme circulaire avec légende et explosion des tranches\n",
    "patches, texts, autotexts = plt.pie(p, labels=p.index, autopct=\"%1.1f%%\", labeldistance=1.1, colors=colors, textprops={'fontsize': 12, 'weight': 'bold'})\n",
    "\n",
    "# Ajouter une légende expliquant les couleurs\n",
    "plt.legend(patches, p.index, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb53e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=data_client.groupby(\"category\")[\"price\"].mean().sort_values(ascending = False).head(3)\n",
    "p\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.pie(p,labels =p.index, rotatelabels =True,autopct=\"%1.1f%%\" , textprops={'fontsize': 12, 'weight': 'bold'});\n",
    "# Ajouter une légende expliquant les couleurs\n",
    "plt.legend(patches, p.index, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig('Les_3_catégories_ayant_les_produits_les_plus_coûteux.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097b2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
